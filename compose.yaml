version: '3'

services:
  whisper:
    build:
      context: ./whisper
      dockerfile: Dockerfile
    volumes:
      - ./data:/data
      - ./models:/models
    ports:
      - "${PORT:-9999}:80"
    environment:
      - MODEL_SIZE=${MODEL_SIZE:-medium}
      - LANGUAGE=${LANGUAGE:-ja}
      - SUMMARIZE_ENABLED=${SUMMARIZE_ENABLED:-true}
      - USE_OLLAMA=${USE_OLLAMA:-true}
      - OLLAMA_API_URL=${OLLAMA_API_URL:-http://host.docker.internal:11434/api/generate}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
    restart: unless-stopped
    # メモリ使用量の制限（要約モデル用）
    mem_limit: 8G
    mem_reservation: 4G
    # ホストネットワークとの接続性を確保（Ollama API用）
    extra_hosts:
      - "host.docker.internal:host-gateway"
    # 初期化スクリプトを実行
    entrypoint: >
      bash -c "
        mkdir -p /data/uploads /data/processed /data/exports /data/logs /data/config /data/cache /data/archives &&
        chown -R www-data:www-data /data /models &&
        chmod -R 775 /data /models &&
        /usr/local/bin/docker-entrypoint.sh
      "

volumes:
  models: